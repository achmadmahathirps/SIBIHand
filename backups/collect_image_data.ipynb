{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b16903a",
   "metadata": {},
   "source": [
    "# 1. Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "033a32f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import cv2 as cv\n",
    "import csv\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01b6cf7",
   "metadata": {},
   "source": [
    "# 2. Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f72296b",
   "metadata": {},
   "source": [
    "## a. Initialize variables and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6c72f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Mediapipe's hand model \n",
    "mediapipe_hands = mp.solutions.hands\n",
    "mediapipe_drawing = mp.solutions.drawing_utils\n",
    "mediapipe_drawing_styles = mp.solutions.drawing_styles\n",
    "hands = mediapipe_hands.Hands(\n",
    "    static_image_mode=True,   \n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.5,\n",
    "    model_complexity=1,\n",
    ")\n",
    "\n",
    "# Initialize main directory \n",
    "path = os.getcwd()\n",
    "main_directory = os.path.dirname(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeec2be0",
   "metadata": {},
   "source": [
    "## b. Initialize functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db223345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract & convert default-normalized landmark keys into absolute pixel value\n",
    "def calc_landmark_list(image, hand_landmarks):\n",
    "\n",
    "    # Initialize image size & new landmark list\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "    landmark_list = []\n",
    "\n",
    "    # Extract & for each landmark keys from detected hand\n",
    "    for _, landmark in enumerate(hand_landmarks.landmark):\n",
    "\n",
    "        # Convert pre-normalized landmark keys into original pixel value\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "\n",
    "        # ! landmark_z is unused due to a bug from Mediapipe Hands when detecting the depth of the hand\n",
    "        # ! and detecting 2 - dimensional datas are much easier to read and explain.\n",
    "        # landmark_z = landmark.z\n",
    "\n",
    "        # Put the converted landmark keys inside the new landmark list\n",
    "        landmark_list.append([landmark_x, landmark_y])\n",
    "\n",
    "    return landmark_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a76487a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert into wrist-relative point coordinates & normalize keys\n",
    "def pre_process_landmark(landmark_list):\n",
    "\n",
    "    # Receive landmark list from calc_landmark_list function\n",
    "    temp_landmark_list = copy.deepcopy(landmark_list)\n",
    "\n",
    "    # Initialize reference key\n",
    "    base_x, base_y = 0, 0\n",
    "\n",
    "    # For each detected landmark keys in landmark list\n",
    "    for index, landmark_point in enumerate(temp_landmark_list):\n",
    "        # If the first index of the landmark list (wrist) is detected,\n",
    "        # set the corresponding landmark keys to reference key\n",
    "        if index == 0:\n",
    "            #base_x, base_y = landmark_point[0], landmark_point[1]\n",
    "            base_x, base_y = landmark_point[0], landmark_point[0]\n",
    "\n",
    "        temp_landmark_list[index][0] = temp_landmark_list[index][0] - base_x\n",
    "        #temp_landmark_list[index][1] = base_y - temp_landmark_list[index][1]\n",
    "        temp_landmark_list[index][1] = base_y - temp_landmark_list[index][1]\n",
    "\n",
    "    # Convert to a one-dimensional matrix list\n",
    "    temp_landmark_list = list(\n",
    "        itertools.chain.from_iterable(temp_landmark_list))\n",
    "\n",
    "    # Find the max value inside the one-dimensional landmark list\n",
    "    max_value = max(list(map(abs, temp_landmark_list)))\n",
    "\n",
    "    # Normalize the relative keys based from the max value\n",
    "    def normalize_value(n):\n",
    "        return n / max_value\n",
    "\n",
    "    # Place & replace landmark list key with new normalized value\n",
    "    temp_landmark_list = list(map(normalize_value, temp_landmark_list))\n",
    "\n",
    "    # Output : return with the new temp_landmark_list value\n",
    "    return temp_landmark_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2adb2a8",
   "metadata": {},
   "source": [
    "## c. Initialize dataset template function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c6a797ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize number of hand keypoints\n",
    "num_coords = 21\n",
    "\n",
    "# Label the corresponding sets of keypoints\n",
    "alphabet = \"B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3b511467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize .csv file\n",
    "def init_csv(feature):\n",
    "    landmarks = ['class']\n",
    "    for val in range(1, num_coords+1):\n",
    "        landmarks += ['x{}'.format(val), 'y{}'.format(val)]\n",
    "\n",
    "    with open(main_directory +'/dataset/03_csv_pre_combined/keypoints_test_{}.csv'.format(feature), mode='w', newline='') as f:\n",
    "    # with open(main_directory +'/dataset/csv_pre_combined/keypoints_test.csv'.format(feature), mode='w', newline='') as f:\n",
    "        csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        csv_writer.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3dd3ac",
   "metadata": {},
   "source": [
    "## d. Initialize dataset logging function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a2ad1714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logging_csv(feature, landmark_list):\n",
    "\n",
    "    csv_path = main_directory + '/dataset/03_csv_pre_combined/keypoints_test_{}.csv'.format(feature)\n",
    "    # csv_path = main_directory + '/dataset/keypoints_test.csv'\n",
    "    \n",
    "    with open(csv_path, 'a', newline=\"\") as f:\n",
    "        writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        writer.writerow([feature, *landmark_list])\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3d9ad2",
   "metadata": {},
   "source": [
    "## e. Initialize image location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "589577a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_FILES = ['SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (1).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (2).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (3).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (4).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (5).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (6).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (7).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (8).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (9).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (10).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (11).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (12).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (13).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (14).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (15).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (16).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (17).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (18).jpg'.format(alphabet, alphabet),\n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (19).jpg'.format(alphabet, alphabet),\n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (20).jpg'.format(alphabet, alphabet),\n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (21).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (22).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (23).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (24).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (25).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (26).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (27).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (28).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (29).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (30).jpg'.format(alphabet, alphabet),\n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (31).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (32).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (33).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (34).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (35).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (36).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (37).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (38).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (39).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (40).jpg'.format(alphabet, alphabet),\n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (41).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (42).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (43).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (44).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (45).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (46).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (47).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (48).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (49).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (50).jpg'.format(alphabet, alphabet)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f9c0f4",
   "metadata": {},
   "source": [
    "# 3. Capture, re-normalize & write landmark keypoints into dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "902d6330",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected : Image B 1\n",
      "Detected : Image B 2\n",
      "Detected : Image B 3\n",
      "Detected : Image B 4\n",
      "Detected : Image B 5\n",
      "Detected : Image B 6\n",
      "Detected : Image B 7\n",
      "Detected : Image B 8\n",
      "Detected : Image B 9\n",
      "Detected : Image B 10\n",
      "Detected : Image B 11\n",
      "Detected : Image B 12\n",
      "Detected : Image B 13\n",
      "Detected : Image B 14\n",
      "Detected : Image B 15\n",
      "Detected : Image B 16\n",
      "Detected : Image B 17\n",
      "Detected : Image B 18\n",
      "Detected : Image B 19\n",
      "Detected : Image B 20\n",
      "Detected : Image B 21\n",
      "Detected : Image B 22\n",
      "Detected : Image B 23\n",
      "Detected : Image B 24\n",
      "Detected : Image B 25\n",
      "Detected : Image B 26\n",
      "Detected : Image B 27\n",
      "Detected : Image B 28\n",
      "Detected : Image B 29\n",
      "Detected : Image B 30\n",
      "Detected : Image B 31\n",
      "Detected : Image B 32\n",
      "Detected : Image B 33\n",
      "Detected : Image B 34\n",
      "Detected : Image B 35\n",
      "[[!]] Not detected : Image B 36\n",
      "[[!]] Not detected : Image B 37\n",
      "Detected : Image B 38\n",
      "[[!]] Not detected : Image B 39\n",
      "Detected : Image B 40\n",
      "Detected : Image B 41\n",
      "Detected : Image B 42\n",
      "Detected : Image B 43\n",
      "Detected : Image B 44\n",
      "Detected : Image B 45\n",
      "Detected : Image B 46\n",
      "Detected : Image B 47\n",
      "Detected : Image B 48\n",
      "Detected : Image B 49\n",
      "Detected : Image B 50\n"
     ]
    }
   ],
   "source": [
    "counter = 1\n",
    "\n",
    "for idx, file in enumerate(IMAGE_FILES):\n",
    "    # Read an image, flip it around y-axis for correct handedness output (see\n",
    "    # above).\n",
    "    image = cv.flip(cv.imread(file), 1)\n",
    "    # Convert the BGR image to RGB before processing.\n",
    "    results = hands.process(cv.cvtColor(image, cv.COLOR_BGR2RGB))\n",
    "    \n",
    "    if not results.multi_hand_landmarks:\n",
    "        print(\"[[!]] Not detected : Image \" + alphabet, counter)\n",
    "        counter += 1\n",
    "        continue\n",
    "    \n",
    "    image_height, image_width, _ = image.shape\n",
    "    debug_image = copy.deepcopy(image)\n",
    "    \n",
    "    if results.multi_hand_landmarks is not None:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "\n",
    "            # Convert pre-normalized landmark keys into pixels numbering\n",
    "            landmark_list = calc_landmark_list(debug_image, hand_landmarks)\n",
    "            \n",
    "            # Convert into relative coordinates / normalize keys from wrist point\n",
    "            pre_processed_landmark_list = pre_process_landmark(landmark_list)\n",
    "            \n",
    "            # Write/log received keypoints into dataset\n",
    "            logging_csv(alphabet, pre_processed_landmark_list)\n",
    "            print('Detected : Image '+ alphabet, counter)\n",
    "            counter += 1\n",
    "            # Visualize complete hand landmarks\n",
    "            mediapipe_drawing.draw_landmarks(\n",
    "                debug_image,\n",
    "                hand_landmarks,\n",
    "                mediapipe_hands.HAND_CONNECTIONS,\n",
    "                mediapipe_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                mediapipe_drawing_styles.get_default_hand_connections_style())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2bd090ec-51aa-4b6f-a008-731fbac8b31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1756, 1687]\n"
     ]
    }
   ],
   "source": [
    "print(landmark_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9d8386-82a8-4b6b-a215-e14b4c34f6cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "531b485039a895d723a85f23ffba8849f89deb444257ba5b9060557527d39769"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
