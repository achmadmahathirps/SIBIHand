Index: detector.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import copy\r\nimport itertools\r\nimport pickle\r\nimport time\r\n\r\nimport cv2 as cv\r\nimport mediapipe as mp\r\nimport numpy as np\r\nimport pandas as pd\r\n\r\n# Initialization #######################################################################################################\r\n\r\n# Initialize colors\r\nblack = (0, 0, 0)\r\ngrey_shade1 = (155, 168, 174)\r\ngrey_shade2 = (188, 202, 208)\r\ngrey_shade3 = (227, 232, 234)\r\nwhite = (255, 255, 255)\r\n\r\n# Initialize camera settings\r\nwebcam = 0\r\ncap = cv.VideoCapture(webcam)\r\ncap.set(cv.CAP_PROP_FRAME_WIDTH, 960)\r\ncap.set(cv.CAP_PROP_FRAME_HEIGHT, 540)\r\n\r\n# Initialize misc.\r\ninit_prev_time = 0\r\nescape_key = 27\r\npress_key = 0xFF\r\n\r\n# Initialize Mediapipe's hand model parameters\r\nmp_hands = mp.solutions.hands\r\nstatic_image_mode = False\r\nmax_num_hands = 1\r\nmin_detection_confidence = 0.8\r\nmin_tracking_confidence = 0.2\r\nmodel_complexity = 0\r\n\r\nhands = mp_hands.Hands(\r\n    static_image_mode=static_image_mode,\r\n    max_num_hands=max_num_hands,\r\n    min_detection_confidence=min_detection_confidence,\r\n    min_tracking_confidence=min_tracking_confidence,\r\n    model_complexity=model_complexity\r\n)\r\n\r\n\r\n# Main program #########################################################################################################\r\ndef main():\r\n    previous_time = init_prev_time\r\n\r\n    # Open & import trained model\r\n    with open('model/svm_trained_classifier.pkl', 'rb') as f:\r\n        model = pickle.load(f)\r\n\r\n    # While in capturing process\r\n    while True:\r\n\r\n        # Application stops when \"ESC\" key is pressed\r\n        if cv.waitKey(5) & press_key == escape_key:\r\n            break\r\n\r\n        # If frame/image in capture is not available left, then stop the application\r\n        available, image = cap.read()\r\n        if not available:\r\n            break\r\n\r\n        # Flip and copy the image for debugging\r\n        image = cv.flip(image, 1)\r\n        debug_image = copy.deepcopy(image)\r\n\r\n        # Convert frame image from BGR to RGB for pre-optimization\r\n        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\r\n\r\n        # Optimize detection process\r\n        image.flags.writeable = False\r\n        results = hands.process(image)\r\n        image.flags.writeable = True\r\n\r\n        # Calculate and visualize FPS indicator\r\n        current_time = time.time()\r\n        fps = 1 / (current_time - previous_time)\r\n        previous_time = current_time\r\n        debug_image = draw_fps(debug_image, fps)\r\n\r\n        # Visualize student info\r\n        debug_image = draw_student_info(debug_image)\r\n\r\n        # If the hand is detected: #####################################################################################\r\n        if results.multi_hand_landmarks is not None:\r\n            for hand_landmarks, handedness in zip(results.multi_hand_landmarks, results.multi_handedness):\r\n                # Calculate boundaries for bounding box\r\n                bounding_box = calc_bounding_box(debug_image, hand_landmarks)\r\n\r\n                # Convert pre-normalized landmark keys into absolute pixel value\r\n                landmark_list = calc_landmark_list(debug_image, hand_landmarks)\r\n\r\n                # Convert into relative coordinates / normalize keys from wrist point\r\n                pre_processed_landmark_list = pre_process_landmark(landmark_list)\r\n\r\n                # Visualize complete hand landmarks\r\n                debug_image = draw_landmarks(debug_image, landmark_list)\r\n\r\n                # Try predict hand gesture and: ########################################################################\r\n                try:\r\n                    hand = pre_processed_landmark_list\r\n\r\n                    data_frame = pd.DataFrame([hand])\r\n                    sign_language_class = model.predict(data_frame)[0]\r\n                    sign_language_prob = model.predict_proba(data_frame)[0]\r\n                    print(sign_language_class, sign_language_prob)\r\n                    print(pre_processed_landmark_list)\r\n\r\n                    # Draw \"Hand detected\" description\r\n                    debug_image = draw_hand_detected(debug_image)\r\n\r\n                    # Draw bounding box with descriptions\r\n                    debug_image = draw_upper_bound_desc(debug_image, bounding_box, sign_language_class)\r\n                    debug_image = draw_bounding_box(True, debug_image, bounding_box)\r\n                    debug_image = draw_lower_bound_desc(debug_image, bounding_box, sign_language_prob)\r\n\r\n                # Finally if not detected, then just pass ##############################################################\r\n                finally:\r\n                    pass\r\n\r\n        # Output frame #################################################################################################\r\n        cv.imshow('Hand (Fingerspelling) Sign Language Recognition', debug_image)\r\n\r\n\r\n# Calculation functions ################################################################################################\r\ndef calc_bounding_box(image, landmarks):\r\n\r\n    image_width, image_height = image.shape[1], image.shape[0]\r\n    landmark_array = np.empty((0, 2), int)\r\n\r\n    for _, landmark in enumerate(landmarks.landmark):\r\n        landmark_x = min(int(landmark.x * image_width), image_width - 1)\r\n        landmark_y = min(int(landmark.y * image_height), image_height - 1)\r\n\r\n        landmark_point = [np.array((landmark_x, landmark_y))]\r\n\r\n        landmark_array = np.append(landmark_array, landmark_point, axis=0)\r\n\r\n    x, y, w, h = cv.boundingRect(landmark_array)\r\n\r\n    return [x, y, x + w, y + h]\r\n\r\n\r\ndef calc_landmark_list(image, landmarks):\r\n    image_width, image_height = image.shape[1], image.shape[0]\r\n\r\n    landmark_point = []\r\n\r\n    # Keypoint\r\n    for _, landmark in enumerate(landmarks.landmark):\r\n        landmark_x = min(int(landmark.x * image_width), image_width - 1)\r\n        landmark_y = min(int(landmark.y * image_height), image_height - 1)\r\n        # landmark_z = landmark.z\r\n\r\n        landmark_point.append([landmark_x, landmark_y])\r\n\r\n    return landmark_point\r\n\r\n\r\ndef pre_process_landmark(landmark_list):\r\n    temp_landmark_list = copy.deepcopy(landmark_list)\r\n\r\n    # Convert to relative coordinates\r\n    base_x, base_y = 0, 0\r\n    for index, landmark_point in enumerate(temp_landmark_list):\r\n        if index == 0:\r\n            base_x, base_y = landmark_point[0], landmark_point[1]\r\n\r\n        temp_landmark_list[index][0] = temp_landmark_list[index][0] - base_x\r\n        temp_landmark_list[index][1] = temp_landmark_list[index][1] - base_y\r\n\r\n    # Convert to a one-dimensional list\r\n    temp_landmark_list = list(\r\n        itertools.chain.from_iterable(temp_landmark_list))\r\n\r\n    # Normalization\r\n    max_value = max(list(map(abs, temp_landmark_list)))\r\n\r\n    def normalize_(n):\r\n        return n / max_value\r\n\r\n    temp_landmark_list = list(map(normalize_, temp_landmark_list))\r\n\r\n    return temp_landmark_list\r\n\r\n\r\n# Cosmetic functions ###################################################################################################\r\ndef draw_student_info(image):\r\n\r\n    x_position = 323\r\n    y_position = 470\r\n    font_size = 0.3\r\n    black_thickness = 2\r\n    white_thickness = 1\r\n\r\n    cv.putText(image, \"* Achmad Mahathir P. (187006041) | Universitas Siliwangi 2022\", (x_position, y_position),\r\n               cv.FONT_HERSHEY_SIMPLEX, font_size,\r\n               black, black_thickness,\r\n               cv.LINE_AA)\r\n    cv.putText(image, \"* Achmad Mahathir P. (187006041) | Universitas Siliwangi 2022\", (x_position, y_position),\r\n               cv.FONT_HERSHEY_SIMPLEX, font_size,\r\n               white, white_thickness,\r\n               cv.LINE_AA)\r\n\r\n    return image\r\n\r\n\r\ndef draw_fps(image, fps):\r\n\r\n    x_position = 10\r\n    y_position = 30\r\n    font_size = 0.73\r\n    black_thickness = 4\r\n    white_thickness = 2\r\n\r\n    cv.putText(image, \"FPS : \" + str(int(fps)), (x_position, y_position), cv.FONT_HERSHEY_SIMPLEX, font_size, black,\r\n               black_thickness,\r\n               cv.LINE_AA)\r\n    cv.putText(image, \"FPS : \" + str(int(fps)), (x_position, y_position), cv.FONT_HERSHEY_SIMPLEX, font_size, white,\r\n               white_thickness,\r\n               cv.LINE_AA)\r\n\r\n    return image\r\n\r\n\r\ndef draw_hand_detected(image):\r\n\r\n    x_position = 10\r\n    y_position = 60\r\n    font_size = 0.73\r\n    black_thickness = 4\r\n    white_thickness = 2\r\n\r\n    cv.putText(image, \"Hand detected\", (x_position, y_position), cv.FONT_HERSHEY_SIMPLEX, font_size,\r\n               black, black_thickness, cv.LINE_AA)\r\n    cv.putText(image, \"Hand detected\", (x_position, y_position), cv.FONT_HERSHEY_SIMPLEX, font_size,\r\n               white, white_thickness, cv.LINE_AA)\r\n\r\n    return image\r\n\r\n\r\ndef draw_upper_bound_desc(image, brect, sign_lang_class):\r\n    cv.rectangle(image, (brect[0], brect[1]), (brect[2], brect[1] - 22), (0, 0, 0), -1)\r\n    sign_alphabet = sign_lang_class.split(' ')[0]\r\n    cv.putText(image, 'Class : ' + sign_alphabet, (brect[0] + 5, brect[1] - 4),\r\n               cv.FONT_HERSHEY_SIMPLEX,\r\n               0.6, black, 2, cv.LINE_AA)\r\n    cv.putText(image, 'Class : ' + sign_alphabet, (brect[0] + 5, brect[1] - 4),\r\n               cv.FONT_HERSHEY_SIMPLEX,\r\n               0.6, white, 1, cv.LINE_AA)\r\n\r\n    return image\r\n\r\n\r\ndef draw_bounding_box(use_brect, image, brect):\r\n    if use_brect:\r\n        # Outer rectangle\r\n        cv.rectangle(image, (brect[0], brect[1]), (brect[2], brect[3]),\r\n                     black, 1)\r\n\r\n    return image\r\n\r\n\r\ndef draw_lower_bound_desc(image, bbox, sign_lang_prob):\r\n    sign_prob = str(round(sign_lang_prob[np.argmax(sign_lang_prob)], 2) * 100)\r\n    cv.rectangle(image, (bbox[2], bbox[3]), (bbox[0], bbox[3] + 22), (0, 0, 0), -1)\r\n    cv.putText(image, 'Prob : ' + sign_prob + \"%\", (bbox[0] + 5, bbox[3] + 17),\r\n               cv.FONT_HERSHEY_SIMPLEX,\r\n               0.6, black, 2, cv.LINE_AA)\r\n    cv.putText(image, 'Prob : ' + sign_prob + \"%\", (bbox[0] + 5, bbox[3] + 17),\r\n               cv.FONT_HERSHEY_SIMPLEX,\r\n               0.6, white, 1, cv.LINE_AA)\r\n\r\n    return image\r\n\r\n\r\ndef draw_landmarks(image, landmark_point):\r\n    if len(landmark_point) > 0:\r\n        # Palm\r\n        cv.line(image, tuple(landmark_point[0]), tuple(landmark_point[1]),\r\n                black, 6)\r\n        cv.line(image, tuple(landmark_point[0]), tuple(landmark_point[1]),\r\n                grey_shade1, 2)\r\n        cv.line(image, tuple(landmark_point[1]), tuple(landmark_point[2]),\r\n                black, 6)\r\n        cv.line(image, tuple(landmark_point[1]), tuple(landmark_point[2]),\r\n                grey_shade2, 2)\r\n        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[5]),\r\n                black, 6)\r\n        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[5]),\r\n                grey_shade1, 2)\r\n        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[0]),\r\n                black, 6)\r\n        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[0]),\r\n                grey_shade1, 2)\r\n        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[9]),\r\n                black, 6)\r\n        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[9]),\r\n                grey_shade1, 2)\r\n        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[13]),\r\n                black, 6)\r\n        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[13]),\r\n                grey_shade1, 2)\r\n        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[17]),\r\n                black, 6)\r\n        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[17]),\r\n                grey_shade1, 2)\r\n        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[0]),\r\n                black, 6)\r\n        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[0]),\r\n                grey_shade1, 2)\r\n\r\n        # Thumb\r\n        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[3]),\r\n                black, 6)\r\n        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[3]),\r\n                grey_shade3, 2)\r\n        cv.line(image, tuple(landmark_point[3]), tuple(landmark_point[4]),\r\n                black, 6)\r\n        cv.line(image, tuple(landmark_point[3]), tuple(landmark_point[4]),\r\n                white, 2)\r\n\r\n        # Index finger\r\n        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[6]),\r\n                black, 6)\r\n        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[6]),\r\n                grey_shade2, 2),\r\n        cv.line(image, tuple(landmark_point[6]), tuple(landmark_point[7]),\r\n                black, 6)\r\n        cv.line(image, tuple(landmark_point[6]), tuple(landmark_point[7]),\r\n                grey_shade3, 2)\r\n        cv.line(image, tuple(landmark_point[7]), tuple(landmark_point[8]),\r\n                black, 6)\r\n        cv.line(image, tuple(landmark_point[7]), tuple(landmark_point[8]),\r\n                white, 2)\r\n\r\n        # Middle finger\r\n        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[10]),\r\n                black, 6)\r\n        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[10]),\r\n                grey_shade2, 2)\r\n        cv.line(image, tuple(landmark_point[10]), tuple(landmark_point[11]),\r\n                black, 6)\r\n        cv.line(image, tuple(landmark_point[10]), tuple(landmark_point[11]),\r\n                grey_shade3, 2)\r\n        cv.line(image, tuple(landmark_point[11]), tuple(landmark_point[12]),\r\n                black, 6)\r\n        cv.line(image, tuple(landmark_point[11]), tuple(landmark_point[12]),\r\n                white, 2)\r\n\r\n        # Ring finger\r\n        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[14]),\r\n                black, 6)\r\n        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[14]),\r\n                grey_shade2, 2)\r\n        cv.line(image, tuple(landmark_point[14]), tuple(landmark_point[15]),\r\n                black, 6)\r\n        cv.line(image, tuple(landmark_point[14]), tuple(landmark_point[15]),\r\n                grey_shade3, 2)\r\n        cv.line(image, tuple(landmark_point[15]), tuple(landmark_point[16]),\r\n                black, 6)\r\n        cv.line(image, tuple(landmark_point[15]), tuple(landmark_point[16]),\r\n                white, 2)\r\n\r\n        # Little finger\r\n        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[18]),\r\n                black, 6)\r\n        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[18]),\r\n                grey_shade2, 2)\r\n        cv.line(image, tuple(landmark_point[18]), tuple(landmark_point[19]),\r\n                black, 6)\r\n        cv.line(image, tuple(landmark_point[18]), tuple(landmark_point[19]),\r\n                grey_shade3, 2)\r\n        cv.line(image, tuple(landmark_point[19]), tuple(landmark_point[20]),\r\n                black, 6)\r\n        cv.line(image, tuple(landmark_point[19]), tuple(landmark_point[20]),\r\n                white, 2)\r\n\r\n    for index, landmark in enumerate(landmark_point):\r\n        if index == 0:\r\n            cv.circle(image, (landmark[0], landmark[1]), 5, white,\r\n                      -1)\r\n            cv.circle(image, (landmark[0], landmark[1]), 5, black, 1)\r\n        if index == 1:\r\n            cv.circle(image, (landmark[0], landmark[1]), 5, white,\r\n                      -1)\r\n            cv.circle(image, (landmark[0], landmark[1]), 5, black, 1)\r\n        if index == 2:\r\n            cv.circle(image, (landmark[0], landmark[1]), 5, white,\r\n                      -1)\r\n            cv.circle(image, (landmark[0], landmark[1]), 5, black, 1)\r\n        if index == 3:\r\n            cv.circle(image, (landmark[0], landmark[1]), 5, white,\r\n                      -1)\r\n            cv.circle(image, (landmark[0], landmark[1]), 5, black, 1)\r\n        if index == 4:\r\n            cv.circle(image, (landmark[0], landmark[1]), 8, white,\r\n                      -1)\r\n            cv.circle(image, (landmark[0], landmark[1]), 8, black, 1)\r\n        if index == 5:\r\n            cv.circle(image, (landmark[0], landmark[1]), 5, white,\r\n                      -1)\r\n            cv.circle(image, (landmark[0], landmark[1]), 5, black, 1)\r\n        if index == 6:\r\n            cv.circle(image, (landmark[0], landmark[1]), 5, white,\r\n                      -1)\r\n            cv.circle(image, (landmark[0], landmark[1]), 5, black, 1)\r\n        if index == 7:\r\n            cv.circle(image, (landmark[0], landmark[1]), 5, white,\r\n                      -1)\r\n            cv.circle(image, (landmark[0], landmark[1]), 5, black, 1)\r\n        if index == 8:\r\n            cv.circle(image, (landmark[0], landmark[1]), 8, white,\r\n                      -1)\r\n            cv.circle(image, (landmark[0], landmark[1]), 8, black, 1)\r\n        if index == 9:\r\n            cv.circle(image, (landmark[0], landmark[1]), 5, white,\r\n                      -1)\r\n            cv.circle(image, (landmark[0], landmark[1]), 5, black, 1)\r\n        if index == 10:\r\n            cv.circle(image, (landmark[0], landmark[1]), 5, white,\r\n                      -1)\r\n            cv.circle(image, (landmark[0], landmark[1]), 5, black, 1)\r\n        if index == 11:\r\n            cv.circle(image, (landmark[0], landmark[1]), 5, white,\r\n                      -1)\r\n            cv.circle(image, (landmark[0], landmark[1]), 5, black, 1)\r\n        if index == 12:\r\n            cv.circle(image, (landmark[0], landmark[1]), 8, white,\r\n                      -1)\r\n            cv.circle(image, (landmark[0], landmark[1]), 8, black, 1)\r\n        if index == 13:\r\n            cv.circle(image, (landmark[0], landmark[1]), 5, white,\r\n                      -1)\r\n            cv.circle(image, (landmark[0], landmark[1]), 5, black, 1)\r\n        if index == 14:\r\n            cv.circle(image, (landmark[0], landmark[1]), 5, white,\r\n                      -1)\r\n            cv.circle(image, (landmark[0], landmark[1]), 5, black, 1)\r\n        if index == 15:\r\n            cv.circle(image, (landmark[0], landmark[1]), 5, white,\r\n                      -1)\r\n            cv.circle(image, (landmark[0], landmark[1]), 5, black, 1)\r\n        if index == 16:\r\n            cv.circle(image, (landmark[0], landmark[1]), 8, white,\r\n                      -1)\r\n            cv.circle(image, (landmark[0], landmark[1]), 8, black, 1)\r\n        if index == 17:\r\n            cv.circle(image, (landmark[0], landmark[1]), 5, white,\r\n                      -1)\r\n            cv.circle(image, (landmark[0], landmark[1]), 5, black, 1)\r\n        if index == 18:\r\n            cv.circle(image, (landmark[0], landmark[1]), 5, white,\r\n                      -1)\r\n            cv.circle(image, (landmark[0], landmark[1]), 5, black, 1)\r\n        if index == 19:\r\n            cv.circle(image, (landmark[0], landmark[1]), 5, white,\r\n                      -1)\r\n            cv.circle(image, (landmark[0], landmark[1]), 5, black, 1)\r\n        if index == 20:\r\n            cv.circle(image, (landmark[0], landmark[1]), 8, white,\r\n                      -1)\r\n            cv.circle(image, (landmark[0], landmark[1]), 8, black, 1)\r\n\r\n    return image\r\n\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/detector.py b/detector.py
--- a/detector.py	(revision ab4f49ed1b84617ee70defeb2cbf4dab95b1b59e)
+++ b/detector.py	(date 1662527688787)
@@ -26,22 +26,14 @@
 # Initialize misc.
 init_prev_time = 0
 escape_key = 27
-press_key = 0xFF
 
 # Initialize Mediapipe's hand model parameters
 mp_hands = mp.solutions.hands
-static_image_mode = False
-max_num_hands = 1
-min_detection_confidence = 0.8
-min_tracking_confidence = 0.2
-model_complexity = 0
-
 hands = mp_hands.Hands(
-    static_image_mode=static_image_mode,
-    max_num_hands=max_num_hands,
-    min_detection_confidence=min_detection_confidence,
-    min_tracking_confidence=min_tracking_confidence,
-    model_complexity=model_complexity
+    static_image_mode=False,
+    max_num_hands=1,
+    min_detection_confidence=0.8,
+    min_tracking_confidence=0.25,
 )
 
 
@@ -57,7 +49,7 @@
     while True:
 
         # Application stops when "ESC" key is pressed
-        if cv.waitKey(5) & press_key == escape_key:
+        if cv.waitKey(5) & 0xFF == escape_key:
             break
 
         # If frame/image in capture is not available left, then stop the application
@@ -92,7 +84,7 @@
                 # Calculate boundaries for bounding box
                 bounding_box = calc_bounding_box(debug_image, hand_landmarks)
 
-                # Convert pre-normalized landmark keys into absolute pixel value
+                # Convert pre-normalized landmark keys into pixels numbering
                 landmark_list = calc_landmark_list(debug_image, hand_landmarks)
 
                 # Convert into relative coordinates / normalize keys from wrist point
@@ -109,7 +101,6 @@
                     sign_language_class = model.predict(data_frame)[0]
                     sign_language_prob = model.predict_proba(data_frame)[0]
                     print(sign_language_class, sign_language_prob)
-                    print(pre_processed_landmark_list)
 
                     # Draw "Hand detected" description
                     debug_image = draw_hand_detected(debug_image)
@@ -129,8 +120,8 @@
 
 # Calculation functions ################################################################################################
 def calc_bounding_box(image, landmarks):
-
     image_width, image_height = image.shape[1], image.shape[0]
+
     landmark_array = np.empty((0, 2), int)
 
     for _, landmark in enumerate(landmarks.landmark):
