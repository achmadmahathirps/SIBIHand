{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efcd0e8a",
   "metadata": {},
   "source": [
    "# 1. Read collected data & pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbfd517a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant dependencies\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17d54a5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize main directory location\n",
    "path = os.getcwd()\n",
    "main_directory = os.path.dirname(path)\n",
    "\n",
    "# Read combined .csv dataset file from previous data collection\n",
    "df = pd.read_csv(main_directory + '/dataset/keypoints_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05aaa793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dataset feature and target values\n",
    "x = df.drop('class', axis=1) # features\n",
    "y = df['class'] # target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "265434ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into 80/20 for training part and testing part\n",
    "# Randomize dataset contents (to avoid possible over-fitting)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6573055e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301    R\n",
      "39     C\n",
      "338    T\n",
      "410    X\n",
      "155    I\n",
      "      ..\n",
      "195    L\n",
      "211    M\n",
      "26     B\n",
      "7      A\n",
      "431    Y\n",
      "Name: class, Length: 137, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02128939",
   "metadata": {},
   "source": [
    "# 2. Train machine learning classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c05250f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant dependencies and model libraries\n",
    "from sklearn.pipeline import make_pipeline \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "from sklearn.svm import SVC, NuSVC, LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bacbde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize training pipelines\n",
    "pipelines = {\n",
    "    'SVM':make_pipeline(StandardScaler(), SVC(probability=True, kernel='linear')),\n",
    "    'NuSVC':make_pipeline(StandardScaler(), NuSVC(probability=True))\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7575d5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(x_train, y_train)\n",
    "    fit_models[algo] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00ba4a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Pipeline.fit of Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('nusvc', NuSVC(probability=True))])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb42060e-8211-4aba-afb1-49faab95b7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SVM': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('svc', SVC(kernel='linear', probability=True))]),\n",
       " 'NuSVC': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('nusvc', NuSVC(probability=True))])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de26681e",
   "metadata": {},
   "source": [
    "# 3. Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b97840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from sklearn.metrics import accuracy_score # Accuracy metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e55a7cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM 0.9927007299270073\n",
      "NuSVC 0.9781021897810219\n"
     ]
    }
   ],
   "source": [
    "# Run training evaluation\n",
    "for algo, model in fit_models.items():\n",
    "    yhat = model.predict(x_test)\n",
    "    print(algo, accuracy_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43e96406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['R', 'C', 'T', 'X', 'I', 'O', 'O', 'F', 'X', 'B', 'E', 'L', 'I',\n",
       "       'U', 'S', 'D', 'J', 'N', 'Q', 'E', 'E', 'H', 'S', 'G', 'W', 'M',\n",
       "       'E', 'Z', 'A', 'P', 'V', 'O', 'Y', 'G', 'Z', 'E', 'Q', 'X', 'H',\n",
       "       'E', 'Q', 'F', 'Y', 'E', 'I', 'E', 'E', 'N', 'X', 'W', 'T', 'B',\n",
       "       'O', 'S', 'J', 'P', 'A', 'W', 'A', 'Z', 'L', 'A', 'B', 'Q', 'U',\n",
       "       'D', 'Y', 'P', 'R', 'L', 'X', 'W', 'B', 'L', 'N', 'Y', 'C', 'P',\n",
       "       'Z', 'G', 'K', 'Q', 'Y', 'B', 'C', 'Z', 'Z', 'H', 'F', 'D', 'I',\n",
       "       'B', 'A', 'D', 'V', 'O', 'B', 'E', 'S', 'H', 'U', 'U', 'F', 'O',\n",
       "       'T', 'X', 'T', 'K', 'G', 'V', 'A', 'C', 'K', 'H', 'W', 'Q', 'A',\n",
       "       'Y', 'V', 'S', 'A', 'B', 'Z', 'D', 'M', 'N', 'V', 'D', 'G', 'Q',\n",
       "       'O', 'B', 'L', 'M', 'B', 'A', 'Y'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models['SVM'].predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98accea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "301    R\n",
       "39     C\n",
       "338    T\n",
       "410    X\n",
       "155    I\n",
       "      ..\n",
       "195    L\n",
       "211    M\n",
       "26     B\n",
       "7      A\n",
       "431    Y\n",
       "Name: class, Length: 137, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d05be0",
   "metadata": {},
   "source": [
    "# 4. Serialize/Export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40e9cb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd42cd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export trained model into specified directory as .pkl file\n",
    "with open(main_directory+'/model/svm_trained_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(fit_models['SVM'], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be1df0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
