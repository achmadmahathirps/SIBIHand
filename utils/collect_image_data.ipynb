{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b16903a",
   "metadata": {},
   "source": [
    "# 1. Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "033a32f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import cv2 as cv\n",
    "import csv\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01b6cf7",
   "metadata": {},
   "source": [
    "# 2. Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f72296b",
   "metadata": {},
   "source": [
    "## a. Initialize variables and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d6c72f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Mediapipe's hand model \n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=True,   \n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.5,\n",
    "    # min_tracking_confidence=0.5,\n",
    "    model_complexity=1,\n",
    ")\n",
    "\n",
    "# Initialize main directory \n",
    "path = os.getcwd()\n",
    "main_directory = os.path.dirname(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeec2be0",
   "metadata": {},
   "source": [
    "## b. Initialize functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db223345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate landmark list \n",
    "def calc_landmark_list(image, landmarks):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    landmark_point = []\n",
    "\n",
    "    # Keypoint\n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "        # landmark_z = landmark.z\n",
    "\n",
    "        landmark_point.append([landmark_x, landmark_y])\n",
    "\n",
    "    return landmark_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a76487a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing calculated landmarks \n",
    "def pre_process_landmark(landmark_list):\n",
    "    temp_landmark_list = copy.deepcopy(landmark_list)\n",
    "\n",
    "    # Convert to relative coordinates\n",
    "    base_x, base_y = 0, 0\n",
    "    for index, landmark_point in enumerate(temp_landmark_list):\n",
    "        if index == 0:\n",
    "            base_x, base_y = landmark_point[0], landmark_point[1]\n",
    "\n",
    "        temp_landmark_list[index][0] = temp_landmark_list[index][0] - base_x\n",
    "        temp_landmark_list[index][1] = base_y - temp_landmark_list[index][1]\n",
    "\n",
    "    # Convert to a one-dimensional list\n",
    "    temp_landmark_list = list(\n",
    "        itertools.chain.from_iterable(temp_landmark_list))\n",
    "\n",
    "    # Normalization\n",
    "    max_value = max(list(map(abs, temp_landmark_list)))\n",
    "\n",
    "    def normalize_(n):\n",
    "        return n / max_value\n",
    "\n",
    "    temp_landmark_list = list(map(normalize_, temp_landmark_list))\n",
    "\n",
    "    return temp_landmark_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2adb2a8",
   "metadata": {},
   "source": [
    "## c. Initialize dataset template function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c6a797ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize number of hand keypoints and alphabet class\n",
    "num_coords = 21\n",
    "alphabet = \"X\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3b511467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize .csv file\n",
    "def init_csv(feature):\n",
    "    landmarks = ['class']\n",
    "    for val in range(1, num_coords+1):\n",
    "        landmarks += ['x{}'.format(val), 'y{}'.format(val)]\n",
    "\n",
    "    with open(main_directory +'/dataset/03_csv_pre_combined/keypoints_{}.csv'.format(feature), mode='w', newline='') as f:\n",
    "    # with open(main_directory +'/dataset/csv_pre_combined/keypoints_test.csv'.format(feature), mode='w', newline='') as f:\n",
    "        csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        csv_writer.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3dd3ac",
   "metadata": {},
   "source": [
    "## d. Initialize dataset logging function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a2ad1714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logging_csv(feature, landmark_list):\n",
    "\n",
    "    csv_path = main_directory + '/dataset/03_csv_pre_combined/keypoints_{}.csv'.format(feature)\n",
    "    # csv_path = main_directory + '/dataset/keypoints_test.csv'\n",
    "    \n",
    "    with open(csv_path, 'a', newline=\"\") as f:\n",
    "        writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        writer.writerow([feature, *landmark_list])\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3d9ad2",
   "metadata": {},
   "source": [
    "## e. Initialize image location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "589577a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_FILES = ['SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (1).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (2).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (3).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (4).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (5).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (6).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (7).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (8).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (9).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (10).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (11).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (12).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (13).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (14).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (15).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (16).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (17).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (18).jpg'.format(alphabet, alphabet),\n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (19).jpg'.format(alphabet, alphabet),\n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (20).jpg'.format(alphabet, alphabet),\n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (21).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (22).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (23).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (24).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (25).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (26).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (27).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (28).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (29).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (30).jpg'.format(alphabet, alphabet),\n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (31).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (32).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (33).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (34).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (35).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (36).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (37).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (38).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (39).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (40).jpg'.format(alphabet, alphabet),\n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (41).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (42).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (43).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (44).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (45).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (46).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (47).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (48).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (49).jpg'.format(alphabet, alphabet), \n",
    "               'SIBI_datasets_LEMLITBANG_SIBI_R_90.10_V02/{}/{} (50).jpg'.format(alphabet, alphabet)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f9c0f4",
   "metadata": {},
   "source": [
    "# 3. Capture, re-normalize & write landmark keypoints into dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "902d6330",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected : Image X 1\n",
      "Detected : Image X 2\n",
      "Detected : Image X 3\n",
      "Detected : Image X 4\n",
      "Detected : Image X 5\n",
      "Detected : Image X 6\n",
      "Detected : Image X 7\n",
      "Detected : Image X 8\n",
      "Detected : Image X 9\n",
      "Detected : Image X 10\n",
      "Detected : Image X 11\n",
      "Detected : Image X 12\n",
      "Detected : Image X 13\n",
      "Detected : Image X 14\n",
      "Detected : Image X 15\n",
      "Detected : Image X 16\n",
      "Detected : Image X 17\n",
      "Detected : Image X 18\n",
      "Detected : Image X 19\n",
      "Detected : Image X 20\n",
      "[[!]] Not detected : Image X 21\n",
      "[[!]] Not detected : Image X 22\n",
      "[[!]] Not detected : Image X 23\n",
      "[[!]] Not detected : Image X 24\n",
      "[[!]] Not detected : Image X 25\n",
      "Detected : Image X 26\n",
      "Detected : Image X 27\n",
      "Detected : Image X 28\n",
      "Detected : Image X 29\n",
      "Detected : Image X 30\n",
      "Detected : Image X 31\n",
      "Detected : Image X 32\n",
      "Detected : Image X 33\n",
      "Detected : Image X 34\n",
      "Detected : Image X 35\n",
      "Detected : Image X 36\n",
      "[[!]] Not detected : Image X 37\n",
      "[[!]] Not detected : Image X 38\n",
      "Detected : Image X 39\n",
      "[[!]] Not detected : Image X 40\n",
      "Detected : Image X 41\n",
      "Detected : Image X 42\n",
      "Detected : Image X 43\n",
      "Detected : Image X 44\n",
      "Detected : Image X 45\n",
      "Detected : Image X 46\n",
      "Detected : Image X 47\n",
      "Detected : Image X 48\n",
      "Detected : Image X 49\n",
      "Detected : Image X 50\n"
     ]
    }
   ],
   "source": [
    "counter = 1\n",
    "\n",
    "for idx, file in enumerate(IMAGE_FILES):\n",
    "    # Read an image, flip it around y-axis for correct handedness output (see\n",
    "    # above).\n",
    "    image = cv.flip(cv.imread(file), 1)\n",
    "    # Convert the BGR image to RGB before processing.\n",
    "    results = hands.process(cv.cvtColor(image, cv.COLOR_BGR2RGB))\n",
    "    \n",
    "    if not results.multi_hand_landmarks:\n",
    "        print(\"[[!]] Not detected : Image \" + alphabet, counter)\n",
    "        counter += 1\n",
    "        continue\n",
    "    \n",
    "    image_height, image_width, _ = image.shape\n",
    "    debug_image = copy.deepcopy(image)\n",
    "    \n",
    "    if results.multi_hand_landmarks is not None:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "\n",
    "            # Convert pre-normalized landmark keys into pixels numbering\n",
    "            landmark_list = calc_landmark_list(debug_image, hand_landmarks)\n",
    "            \n",
    "            # Convert into relative coordinates / normalize keys from wrist point\n",
    "            pre_processed_landmark_list = pre_process_landmark(landmark_list)\n",
    "            \n",
    "            # Write/log received keypoints into dataset\n",
    "            logging_csv(alphabet, pre_processed_landmark_list)\n",
    "            print('Detected : Image '+ alphabet, counter)\n",
    "            counter += 1\n",
    "            # Visualize complete hand landmarks\n",
    "            mp_drawing.draw_landmarks(\n",
    "                debug_image,\n",
    "                hand_landmarks,\n",
    "                mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                mp_drawing_styles.get_default_hand_connections_style())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70f7876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed6d56b-aa97-4a3b-bc44-dc77a510ae51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "531b485039a895d723a85f23ffba8849f89deb444257ba5b9060557527d39769"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
